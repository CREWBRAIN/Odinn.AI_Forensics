# Functional Requirements Document: ğŸ§Š Odinn AI Forensics Tool

## 1. Introduction

### 1.1 Purpose

This document outlines the functional requirements for ğŸ§Š Odinn AI Forensics Tool, a research-oriented PDF processing tool designed to extract text, metadata, images, and bounding box data from PDF documents, perform vision cleaning on extracted text using LLaVA, and generate a comprehensive, well-organized output package suitable for research and citation.

### 1.2 Scope

ğŸ§Š Odinn AI Forensics Tool will be a standalone Python script that leverages the `marker` package for PDF processing and the `litellm` library for interacting with the LLaVA vision cleaning model. It will feature a rich text-based user interface (TUI) built using the `rich` library to provide an interactive and user-friendly experience.

## 2. Functional Requirements

### 2.1 PDF Loading

- **FR-1:** The system shall allow the user to load a single PDF file.
- **FR-2:** The system shall validate the selected file to ensure it is a PDF document.
- **FR-3:** The system shall handle file loading errors gracefully and provide informative error messages to the user.

### 2.2 Settings Configuration

- **FR-4:** The system shall provide a settings menu accessible from the main menu.
- **FR-5:** The settings menu shall allow the user to configure the following settings:
  - **Marker Settings:**
    - **FR-5.1:** Torch device (CPU, GPU, MPS) - automatically detected with override option.
    - **FR-5.2:** OCR engine (Surya, OCRMyPDF, None) - selectable with appropriate dependency handling.
    - **FR-5.3:** Languages for OCR - comma-separated list of languages or language codes.
    - **FR-5.4:** Batch multiplier - integer value to scale batch sizes for improved performance.
    - **FR-5.5:** Bounding Box Options:
      - **FR-5.5.1:** Extract bounding boxes (True/False)
      - **FR-5.5.2:** Bounding box types to extract (list, selectable from available types in `marker.schema.bbox`)
      - **FR-5.5.3:** Visualize bounding boxes on extracted images (True/False)
    - **FR-5.6:** Other relevant settings from `marker.settings` (e.g., `OCR_ALL_PAGES`, `PAGINATE_OUTPUT`, `EXTRACT_IMAGES`).
  - **Vision Cleaning Settings:**
    - **FR-5.7:** Model to use (e.g., "ollama/llava-phi3")
    - **FR-5.8:** Prompt structure and metadata inclusion options.
  - **Output Settings:**
    - **FR-5.9:** Output folder path.
    - **FR-5.10:** Citation information (title, author, publication date, etc.).
- **FR-6:** The system shall allow the user to save the current settings to a file.
- **FR-7:** The system shall allow the user to load settings from a file.

### 2.3 Metadata Management

- **FR-8:** The system shall allow the user to input metadata for the document using interactive prompts.
- **FR-9:** The system shall extract metadata from the cleaned text generated by the vision cleaning process.
- **FR-10:** The system shall merge user-provided metadata and extracted metadata, handling potential conflicts or inconsistencies.

### 2.4 Page Processing

- **FR-11:** The system shall extract text, metadata, and images from each page of the PDF document using `marker.convert.convert_single_pdf`.
- **FR-12:** The system shall extract page images with and without bounding boxes, based on the user's settings.
- **FR-13:** The system shall save page data (text, metadata, images) to organized subfolders within a project folder.

### 2.5 Vision Cleaning

- **FR-14:** The system shall allow the user to select specific pages for vision cleaning.
- **FR-15:** The system shall process the selected pages using the LLaVA vision cleaning model, providing the extracted text, image with bounding boxes, and combined metadata as input.
- **FR-16:** The system shall extract metadata from the cleaned text.
- **FR-17:** The system shall save the cleaned text and extracted metadata to the appropriate subfolders.

### 2.6 Output Package Generation

- **FR-18:** The system shall create a comprehensive project folder for each processed PDF document.
- **FR-19:** The project folder shall contain the following subfolders:
  - `original_pdf`: Containing the original PDF file.
  - `page_images`: Containing individual page images without bounding boxes.
  - `page_images_bboxes`: Containing individual page images with bounding boxes visualized.
  - `page_data`: Containing individual page data (text, metadata, cleaned text, TOC, font analysis, structural analysis, language information).
- **FR-20:** The system shall generate a summary report at the end of the processing, including:
  - Path to the project folder.
  - Number of pages processed.
  - Errors or warnings encountered.
  - Summary of the document's structure (if extracted).
  - Citation information.

### 2.7 State Saving

- **FR-21:** The system shall define a state object to represent the current state of the processing pipeline.
- **FR-22:** The system shall provide a function to save the state object to a JSON file.
- **FR-23:** The system shall provide a function to load a previously saved state from a JSON file.
- **FR-24:** The system shall automatically save the state after each step in the "Uber Step" processing mode.
- **FR-25:** The system shall provide an option to save the state manually in the step-by-step processing mode.
- **FR-26:** The system shall provide an option to load a saved state from the main menu.

### 2.8 Advanced Text Analysis

- **FR-31:** The system shall perform Named Entity Recognition (NER) on the extracted text using an NLP library (e.g., spaCy).
- **FR-32:** The system shall identify and classify entities such as people, organizations, locations, dates, and other relevant types.
- **FR-33:** The system shall use NER results for:
  - **FR-33.1:** Automatic metadata extraction (e.g., author names, publication dates).
  - **FR-33.2:** Content analysis to identify topics and themes.
  - **FR-33.3:** Creation of a searchable index based on identified entities.
- **FR-34:** The system shall perform sentiment analysis on the extracted text to determine the overall sentiment (positive, negative, neutral).
- **FR-35:** The system shall use sentiment analysis results for:
  - **FR-35.1:** Document classification based on sentiment.
  - **FR-35.2:** Opinion mining to understand author or public sentiment.
- **FR-36:** The system shall provide text summarization capabilities for the entire document or selected sections.

### 2.9 Enhanced Layout Analysis

- **FR-37:** The system shall automatically detect sections and subsections in the document using layout information from `marker`.
- **FR-38:** The system shall use section detection results to:
  - **FR-38.1:** Create a structured outline of the document's content.
  - **FR-38.2:** Improve navigation in the output markdown by linking to specific sections.
- **FR-39:** The system shall improve the extraction of captions for figures and tables using `marker`'s layout analysis.

### 2.10 Integration with External Tools

- **FR-40:** The system shall provide an option to integrate with citation management software (e.g., Zotero, Mendeley).
- **FR-41:** The system shall use extracted citation information to automatically create entries in the user's citation library.
- **FR-42:** The system shall provide an option to translate the extracted text into different languages using a translation API.
- **FR-43:** The system shall provide an option to generate an audio version of the document using a text-to-speech engine.

### 2.11 Interactive TUI Features

- **FR-44:** The system shall allow users to interactively select bounding boxes on displayed page images within the TUI.
- **FR-45:** Interactive bounding box selection shall be used for:
  - **FR-45.1:** Correcting errors in `marker`'s automatic bounding box detection.
  - **FR-45.2:** Selecting specific regions of interest for vision cleaning.
- **FR-46:** The system shall display a preview of the cleaned text within the TUI after vision cleaning.
- **FR-47:** The system shall allow users to edit or correct the cleaned text preview before saving.



### 3. Project Structure and User Interface
```
odinn_ai_forensics_tool/
â”œâ”€â”€ marker/  # Folder for the marker package files
â”‚   â”œâ”€â”€ convert.py
â”‚   â”œâ”€â”€ pdf/
â”‚   â”‚   â””â”€â”€ extract_text.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ ... (other marker files)
â”œâ”€â”€ ai_forensics.py  # Main script
â”œâ”€â”€ utils.py  # Utility functions
â”œâ”€â”€ settings.py  # Settings management
â”œâ”€â”€ vision_cleaning.py  # Vision cleaning logic
â””â”€â”€ ... (other project files)
```


- **FR-27:** The system shall provide a rich TUI using the `rich` library.
- **FR-28:** The TUI shall include the following menus and options:
  - **Main Menu:**
    - Load PDF
    - Settings
    - Process PDF (Step-by-Step)
    - Process PDF (Uber Step)
    - Exit
  - **Settings Submenu:** (See FR-5 for settings options)
    - Save Settings
    - Load Settings
  - **Step-by-Step Processing Submenu:**
    - Extract Text and Metadata (Marker)
    - Extract Images
      - Without Bounding Boxes
      - With Bounding Boxes
    - Vision Cleaning
    - Generate Output Package
- **FR-29:** The TUI shall use clear and concise prompts to guide the user.
- **FR-30:** The TUI shall provide informative messages and progress indicators to keep the user updated on the status of the processing.

### 4. Pseudocode

```python
# ai_forensics.py (Main Script)

# Imports
import os
import shutil
import json
import logging
from typing import List, Dict, Any, Optional

import pypdfium2 as pdfium
from pdf2image import convert_from_path
from PIL import Image, ImageDraw
import litellm
from litellm import completion
from rich.console import Console
from rich.prompt import Prompt, Confirm, IntPrompt, ListPrompt
from rich.progress import Progress, track
from rich.table import Table
from rich.panel import Panel

# Import from local marker package
from marker.convert import convert_single_pdf
from marker.pdf.extract_text import get_toc
from marker.settings import settings as marker_settings

# Import project modules
from utils import create_directories, save_file, save_image, extract_image_with_bboxes
from settings import Settings
from vision_cleaning import VisionCleanProcessor, process_vision_clean

# Configure logging
logging.basicConfig(level=logging.DEBUG)  # Set log level to DEBUG for verbose logging
console = Console()

# --- Settings Management ---
def load_settings_from_file(filepath: str) -> Optional[Settings]:
    """Loads settings from a JSON file."""
    try:
        with open(filepath, 'r') as f:
            data = json.load(f)
        settings = Settings()
        settings.load_from_dict(data)  # Assuming Settings has a load_from_dict method
        return settings
    except FileNotFoundError:
        console.print(f"[bold red]Error: Settings file not found: {filepath}[/]")
        return None
    except json.JSONDecodeError:
        console.print(f"[bold red]Error: Invalid JSON in settings file: {filepath}[/]")
        return None

# --- Main Processing Functions ---
def process_page(doc: pdfium.PdfDocument, page_num: int, settings: Settings, output_folder: str) -> Tuple[str, Dict, Dict[str, Image.Image]]:
    """Processes a single page of the PDF."""
    console.print(f"ğŸ§Š Odinn.Orchestrator: Processing page {page_num + 1}...", style="bold green")
    page_text, images, page_meta = convert_single_pdf(
        doc, 
        model_lst=None,  # Models are loaded once at the beginning
        max_pages=1, 
        langs=settings.langs, 
        batch_multiplier=settings.batch_multiplier, 
        start_page=page_num
    )
    console.print(f"ğŸ§Š Odinn.Orchestrator: Extracting page {page_num + 1} images...", style="bold green")
    # Extract images using pdf2image
    images_with_bboxes = convert_from_path(doc.file_path, first_page=page_num + 1, last_page=page_num + 1)
    # Assuming the image with bounding boxes is the first one in the list
    image_with_bboxes = images_with_bboxes[0] 

    # Extract bounding boxes if enabled
    bboxes = []
    if settings.extract_bboxes:
        bboxes = page_meta.get('detected_bboxes', [])  # Get bounding boxes from marker output

    # Visualize bounding boxes on the image
    if settings.visualize_bboxes:
        draw = ImageDraw.Draw(image_with_bboxes)
        for bbox in bboxes:
            if settings.bbox_types and bbox["label"] not in settings.bbox_types:
                continue
            coords = bbox["coords"]
            draw.rectangle(coords, outline="red", width=2)

    # Save the images
    image_folder = os.path.join(output_folder, "page_images")
    image_filename = f"page_{page_num + 1}.jpg"
    save_image(image_with_bboxes, os.path.join(image_folder, image_filename))

    image_with_bboxes_folder = os.path.join(output_folder, "page_images_bboxes")
    image_with_bboxes_filename = f"page_{page_num + 1}_bboxes.jpg"
    save_image(image_with_bboxes, os.path.join(image_with_bboxes_folder, image_with_bboxes_filename))

    console.print(f"ğŸ§Š Odinn.Orchestrator: Page {page_num + 1} processed.", style="bold green")
    return page_text, page_meta, images

def process_pdf(filename: str, output_folder: str, settings: Settings, user_metadata: Optional[Dict] = None) -> None:
    """Processes a single PDF file and creates a comprehensive output package."""
    base_name = os.path.basename(filename).rsplit(".", 1)[0]
    project_folder = os.path.join(output_folder, base_name)

    # Create project folder and subfolders
    create_directories(project_folder, ["original_pdf", "page_images", "page_images_bboxes", "page_data"])

    # Copy original PDF
    shutil.copy(filename, os.path.join(project_folder, "original_pdf", base_name + ".pdf"))

    console.print(f"\nğŸ§Š Odinn.Orchestrator: Loading forensic models...  â™»ï¸  \n", style="bold green")
    model_lst = load_all_models()  # Load models once

    doc = pdfium.PdfDocument(filename)
    total_pages = len(doc)
    doc.file_path = filename  # Store the file path in the document object

    for page_num in range(total_pages):
        page_text, page_meta, images = process_page(doc, page_num, settings, project_folder)

        # Save page data
        subfolder_path, text_filename = save_page_data(
            project_folder, base_name, page_num + 1, page_text, images, page_meta
        )

        # Vision Clean process with combined metadata
        combined_metadata = merge_metadata(user_metadata, {})  # Initially empty vision cleaning metadata
        cleaned_text = process_vision_clean(os.path.join(project_folder, "page_images_bboxes", f"page_{page_num + 1}_bboxes.jpg"), text_filename, combined_metadata)
        cleaned_text_filename = os.path.join(subfolder_path, "cleaned_text", f"{base_name}_pg{page_num + 1}_cleaned.txt")
        save_file(cleaned_text, cleaned_text_filename)
        console.print(f"\nğŸ§Š Odinn.Orchestrator: Cleaned text for page {page_num + 1} saved to {cleaned_text_filename}.    \n", style="bold green")

        # Extract metadata from cleaned text
        vision_cleaning_metadata = extract_metadata_from_text(cleaned_text)
        # ... (save vision cleaning metadata)

        # Update combined metadata
        combined_metadata = merge_metadata(user_metadata, vision_cleaning_metadata)
        # ... (save combined metadata)

    # Extract and save TOC
    toc = get_toc(doc)
    save_file(json.dumps(toc, indent=4), os.path.join(project_folder, "page_data", "toc.json"))

    # ... (perform font analysis, structural analysis, language identification)

    # Generate summary report
    console.print(f"\nğŸ§Š Odinn.Orchestrator: Processing complete!  ğŸ‘  \n", style="bold green")
    console.print(f"Project folder: {project_folder}")
    # ... (print other summary information)

# --- TUI Functions ---
def display_main_menu():
    """Displays the main menu options."""
    table = Table(title="ğŸ§Š Odinn AI Forensics Tool")
    table.add_column("Option", style="cyan", width=12)
    table.add_column("Description", style="magenta")
    table.add_row("[1]", "Load PDF")
    table.add_row("[2]", "Settings")
    table.add_row("[3]", "Process PDF (Step-by-Step)")
    table.add_row("[4]", "Process PDF (Uber Step)")
    table.add_row("[5]", "Load Saved State")
    table.add_row("[6]", "Exit")
    console.print(table)

def display_settings_menu(settings: Settings):
    """Displays the settings menu."""
    console.print(Panel(f"[bold blue]Current Settings:[/]\n{settings}", title="Settings", expand=False))

    while True:
        options = [
            "Torch Device",
            "OCR Engine",
            "Languages",
            "Batch Multiplier",
            "Bounding Box Options",
            "Output Folder",
            "Citation Information",
            "Save Settings",
            "Load Settings",
            "Back to Main Menu"
        ]
        choice = Prompt.ask("Select an option", choices=[str(i+1) for i in range(len(options))], default=str(len(options)))

        if choice == str(len(options)):
            break  # Back to main menu

        choice_index = int(choice) - 1
        option = options[choice_index]

        if option == "Torch Device":
            devices = ["cpu", "cuda", "mps"]
            device_choice = Prompt.ask("Select Torch device", choices=devices, default=settings.torch_device)
            settings.torch_device = device_choice
        elif option == "OCR Engine":
            engines = ["surya", "ocrmypdf", "None"]
            engine_choice = Prompt.ask("Select OCR engine", choices=engines, default=settings.ocr_engine)
            settings.ocr_engine = engine_choice if engine_choice != "None" else None
        elif option == "Languages":
            langs_str = Prompt.ask("Enter languages (comma-separated)", default=", ".join(settings.langs) if settings.langs else "")
            settings.langs = [lang.strip() for lang in langs_str.split(",")] if langs_str else None
        elif option == "Batch Multiplier":
            settings.batch_multiplier = IntPrompt.ask("Enter batch multiplier", default=settings.batch_multiplier)
        elif option == "Bounding Box Options":
            display_bounding_box_options(settings)
        elif option == "Output Folder":
            settings.output_folder = Prompt.ask("Enter output folder path", default=settings.output_folder)
        elif option == "Citation Information":
            settings.citation["title"] = Prompt.ask("Enter document title:", default=settings.citation.get("title", ""))
            settings.citation["author"] = Prompt.ask("Enter document author:", default=settings.citation.get("author", ""))
            # ... (Prompt for other citation fields)
        elif option == "Save Settings":
            filepath = Prompt.ask("Enter settings file path to save:")
            settings.save_to_file(filepath)
        elif option == "Load Settings":
            filepath = Prompt.ask("Enter settings file path to load:")
            loaded_settings = load_settings_from_file(filepath)
            if loaded_settings:
                settings = loaded_settings

def display_bounding_box_options(settings: Settings):
    """Displays the bounding box options menu."""
    while True:
        console.print(Panel(
            f"[bold blue]Bounding Box Options:[/]\n"
            f"Extract Bounding Boxes: {settings.extract_bboxes}\n"
            f"Bounding Box Types: {', '.join(settings.bbox_types) if settings.bbox_types else 'All'}\n"
            f"Visualize Bounding Boxes: {settings.visualize_bboxes}",
            title="Bounding Box Options",
            expand=False
        ))

        options = [
            "Toggle Extract Bounding Boxes",
            "Select Bounding Box Types",
            "Toggle Visualize Bounding Boxes",
            "Back to Settings"
        ]
        choice = Prompt.ask("Select an option", choices=[str(i+1) for i in range(len(options))], default=str(len(options)))

        if choice == str(len(options)):
            break  # Back to settings menu

        choice_index = int(choice) - 1
        option = options[choice_index]

        if option == "Toggle Extract Bounding Boxes":
            settings.extract_bboxes = not settings.extract_bboxes
        elif option == "Select Bounding Box Types":
            available_types = ["Table", "Figure", "Formula", "Section-Header", "Title", "List-Item", "Code"]  # Get from marker.schema.bbox
            selected_types = ListPrompt.ask("Select bounding box types", choices=available_types, default=settings.bbox_types)
            settings.bbox_types = selected_types
        elif option == "Toggle Visualize Bounding Boxes":
            settings.visualize_bboxes = not settings.visualize_bboxes

def display_step_by_step_menu(filename: str, output_folder: str, settings: Settings, user_metadata: Optional[Dict] = None):
    """Displays the step-by-step processing menu."""
    doc = pdfium.PdfDocument(filename)
    total_pages = len(doc)

    while True:
        table = Table(title="Step-by-Step Processing")
        table.add_column("Option", style="cyan", width=12)
        table.add_column("Description", style="magenta")
        table.add_row("[1]", "Extract Text and Metadata (Marker)")
        table.add_row("[2]", "Extract Images")
        table.add_row("[3]", "Vision Cleaning")
        table.add_row("[4]", "Generate Output Package")
        table.add_row("[5]", "Save Current State")
        table.add_row("[6]", "Back to Main Menu")
        console.print(table)

        choice = Prompt.ask("Enter option", choices=["1", "2", "3", "4", "5", "6"], default="6")

        if choice == "1":
            with Progress() as progress:
                for page_num in track(range(total_pages), description="Extracting text and metadata..."):
                    process_page(doc, page_num, settings, output_folder)
        elif choice == "2":
            display_image_extraction_menu(doc, settings, output_folder)
        elif choice == "3":
            # ... (Implement vision cleaning for selected pages)
        elif choice == "4":
            # ... (Implement output package generation)
        elif choice == "5":
            # ... (Implement state saving)
        elif choice == "6":
            break  # Back to main menu

def display_image_extraction_menu(doc: pdfium.PdfDocument, settings: Settings, output_folder: str):
    """Displays the image extraction options menu."""
    total_pages = len(doc)

    while True:
        table = Table(title="Image Extraction")
        table.add_column("Option", style="cyan", width=12)
        table.add_column("Description", style="magenta")
        table.add_row("[1]", "Extract All Images (No Bounding Boxes)")
        table.add_row("[2]", "Extract All Images (With Bounding Boxes)")
        table.add_row("[3]", "Back to Step-by-Step Menu")
        console.print(table)

        choice = Prompt.ask("Enter option", choices=["1", "2", "3"], default="3")

        if choice == "1":
            with Progress() as progress:
                for page_num in track(range(total_pages), description="Extracting images..."):
                    _, _, images = process_page(doc, page_num, settings, output_folder)
                    # ... (Save images without bounding boxes)
        elif choice == "2":
            with Progress() as progress:
                for page_num in track(range(total_pages), description="Extracting images with bounding boxes..."):
                    _, _, images = process_page(doc, page_num, settings, output_folder)
                    # ... (Save images with bounding boxes)
        elif choice == "3":
            break  # Back to step-by-step menu

# --- Main Function ---
def main():
    """Main function to run the TUI."""
    settings = Settings()
    user_metadata = None
    filename = None
    model_lst = None

    while True:
        os.system("cls" if os.name == "nt" else "clear")
        display_main_menu()
        choice = Prompt.ask("Enter option", choices=["1", "2", "3", "4", "5", "6"], default="1")

        if choice == "1":
            filename = Prompt.ask("Enter PDF file path:")
            if not os.path.exists(filename):
                console.print(f"[bold red]Error: File not found: {filename}[/]")
                filename = None
            else:
                console.print(f"Loaded PDF: {filename}")
        elif choice == "2":
            display_settings_menu(settings)
        elif choice == "3":
            if filename:
                display_step_by_step_menu(filename, settings.output_folder, settings, user_metadata)
            else:
                console.print("[bold red]Error: No PDF loaded.[/]")
        elif choice == "4":
            if filename:
                user_metadata = get_user_metadata()
                process_pdf(filename, settings.output_folder, settings, user_metadata)
            else:
                console.print("[bold red]Error: No PDF loaded.[/]")
        elif choice == "5":
            state_filepath = Prompt.ask("Enter state file path to load:")
            state = load_state(state_filepath)
            if state:
                # ... (Load settings, filename, user_metadata, and other state information)
                console.print(f"Loaded state from: {state_filepath}")
        elif choice == "6":
            console.print("Exiting ğŸ§Š Odinn AI Forensics Tool...")
            break

if __name__ == "__main__":
    main()
```

### 5. Implementation Notes

- **Modularity:** Design the code with modularity in mind. Create separate functions or classes for each feature to make it easier to add, remove, or modify functionality.
- **Configuration:** Allow users to enable or disable specific features through the settings menu. This will give them more control over the processing pipeline.
- **Plugins:** Consider a plugin architecture to allow users to extend the functionality of the script with their own custom features.

### 6. Additional Considerations

- **Performance:**  For computationally intensive features like NER, sentiment analysis, and summarization, consider providing options to process only selected pages or sections to improve performance.
- **User Feedback:**  Provide clear and informative feedback to the user during long-running processes. Use progress bars, status messages, and visual cues to keep the user informed.
- **Error Handling:** Implement robust error handling to gracefully handle unexpected situations and prevent data loss.

This updated FRD incorporates the advanced features you requested, making the ğŸ§Š Odinn AI Forensics Tool a truly powerful and versatile PDF processing solution. 
--

# Last Steps:

**1. Thorough Testing:**

   - **Unit Tests:** Create unit tests for individual functions and modules (e.g., `settings.py`, `utils.py`, `vision_cleaning.py`). This will help ensure that each component works correctly in isolation.
   - **Integration Tests:** Test the entire pipeline with a variety of PDF documents, especially City of Manila ordinances from different councils. This will help identify and fix any integration issues or unexpected behavior.
   - **Edge Case Testing:** Test the script with PDFs that might present challenges, such as:
     - PDFs with complex layouts or unusual formatting.
     - PDFs with poor-quality OCR or scanned images.
     - PDFs in different languages.
     - Very large PDFs.
   - **Error Handling Tests:**  Intentionally introduce errors (e.g., invalid file paths, incorrect settings) to ensure that the error handling mechanisms work correctly and provide informative messages to the user.

**2. Refinement and Optimization:**

   - **User Feedback:**  Have users interact with the TUI and provide feedback on usability, clarity, and any missing or desired features.
   - **Performance:**  Profile the script's performance with large PDFs and optimize any bottlenecks. Consider using multiprocessing or asynchronous operations to improve speed.
   - **Code Quality:** Review the code for readability, maintainability, and adherence to coding standards. Refactor as needed.
   - **Documentation:**  Write clear and concise documentation for the script, including instructions for installation, usage, and configuration.

**3. Additional Features (Optional):**

   - **Structural Analysis:** Implement more sophisticated structural analysis in the `generate_output_package` function. For example, you could use NLP techniques to identify headings, sections, and other structural elements.
   - **Language Identification:**  Add language identification to the `generate_output_package` function. You could use an NLP library or a language detection API.
   - **Interactive Bounding Box Selection:** Implement the interactive bounding box selection feature (FR-44 and FR-45) in the TUI. This would require displaying the page images and allowing the user to draw or adjust bounding boxes.
   - **Cleaned Text Preview:** Implement the cleaned text preview feature (FR-46 and FR-47) in the TUI. This would allow users to review and edit the cleaned text before saving it.
   - **Citation Management Integration:**  Implement the integration with citation management software (FR-40 and FR-41).
   - **Translation and Text-to-Speech:** Implement the translation (FR-42) and text-to-speech (FR-43) features.

**4. Deployment:**

   - **Packaging:** Package the script and its dependencies for easy distribution and installation.
   - **User Instructions:** Create clear and concise instructions for users on how to install, configure, and use the tool.

**Summary:**

We've built a solid foundation for the ğŸ§Š Odinn AI Forensics Tool, but thorough testing, refinement, and potentially the addition of more advanced features are essential to make it a truly robust and valuable tool for processing government documents. 

# Complete Set:
## Project Structure

```
odinn_ai_forensics_tool/
â”œâ”€â”€ ai_forensics.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ settings.py
â””â”€â”€ vision_cleaning.py 
```

## File Contents:

**1. `ai_forensics.py` (Main Script):**

```python
import os
import shutil
import json
import logging
from typing import List, Dict, Any, Optional

import pypdfium2 as pdfium
from pdf2image import convert_from_path
from PIL import Image, ImageDraw
import litellm
from litellm import completion
from rich.console import Console
from rich.prompt import Prompt, Confirm, IntPrompt, ListPrompt
from rich.progress import Progress, track
from rich.table import Table
from rich.panel import Panel

# Import from local marker package
from marker.convert import convert_single_pdf
from marker.pdf.extract_text import get_toc
from marker.settings import settings as marker_settings

# Import project modules
from utils import create_directories, save_file, save_image, extract_image_with_bboxes, get_subfolder_path
from settings import Settings
from vision_cleaning import VisionCleanProcessor, process_vision_clean

# Configure logging
logging.basicConfig(level=logging.DEBUG)  # Set log level to DEBUG for verbose logging
console = Console()

# --- State Management ---
def save_state(state: Dict, filepath: str) -> None:
    """Saves the processing state to a JSON file."""
    with open(filepath, 'w') as f:
        json.dump(state, f, indent=4)

def load_state(filepath: str) -> Optional[Dict]:
    """Loads the processing state from a JSON file."""
    try:
        with open(filepath, 'r') as f:
            state = json.load(f)
        return state
    except FileNotFoundError:
        console.print(f"[bold red]Error: State file not found: {filepath}[/]")
        return None
    except json.JSONDecodeError:
        console.print(f"[bold red]Error: Invalid JSON in state file: {filepath}[/]")
        return None

# --- Metadata Functions ---
def get_user_metadata() -> Dict:
    """Prompts the user for metadata input."""
    user_metadata = {}
    user_metadata["title"] = Prompt.ask("Enter ordinance title:")
    user_metadata["council"] = Prompt.ask("Enter council number (1-13):", choices=[str(i) for i in range(1, 14)])
    user_metadata["ordinance_number"] = Prompt.ask("Enter ordinance number:")
    user_metadata["year"] = Prompt.ask("Enter year:")
    # ... (Prompt for other metadata fields as needed)
    return user_metadata

def extract_metadata_from_text(text: str) -> Dict:
    """Extracts metadata from cleaned text using regex."""
    extracted_metadata = {}
    # Example: Extract ordinance number using regex
    import re
    match = re.search(r'Ordinance No\. (\d+-\d+)', text)
    if match:
        extracted_metadata["ordinance_number"] = match.group(1)
    # ... (Add more regex patterns to extract other metadata)
    return extracted_metadata

def merge_metadata(user_metadata: Dict, extracted_metadata: Dict) -> Dict:
    """Merges user-provided and extracted metadata."""
    merged_metadata = user_metadata.copy()
    for key, value in extracted_metadata.items():
        if key not in merged_metadata or not merged_metadata[key]:  # Prioritize user input
            merged_metadata[key] = value
    return merged_metadata

# --- Main Processing Functions ---
def process_page(doc: pdfium.PdfDocument, page_num: int, settings: Settings, output_folder: str) -> Tuple[str, Dict, Dict[str, Image.Image]]:
    """Processes a single page of the PDF."""
    console.print(f"ğŸ§Š Odinn.Orchestrator: Processing page {page_num + 1}...", style="bold green")
    page_text, images, page_meta = convert_single_pdf(
        doc, 
        model_lst=None,  # Models are loaded once at the beginning
        max_pages=1, 
        langs=settings.langs, 
        batch_multiplier=settings.batch_multiplier, 
        start_page=page_num
    )
    console.print(f"ğŸ§Š Odinn.Orchestrator: Extracting page {page_num + 1} images...", style="bold green")
    # Extract images using pdf2image
    images_with_bboxes = convert_from_path(doc.file_path, first_page=page_num + 1, last_page=page_num + 1)
    # Assuming the image with bounding boxes is the first one in the list
    image_with_bboxes = images_with_bboxes[0] 

    # Extract bounding boxes if enabled
    bboxes = []
    if settings.extract_bboxes:
        bboxes = page_meta.get('detected_bboxes', [])  # Get bounding boxes from marker output

    # Visualize bounding boxes on the image
    if settings.visualize_bboxes:
        draw = ImageDraw.Draw(image_with_bboxes)
        for bbox in bboxes:
            if settings.bbox_types and bbox["label"] not in settings.bbox_types:
                continue
            coords = bbox["coords"]
            draw.rectangle(coords, outline="red", width=2)

    # Save the images
    image_folder = os.path.join(output_folder, "page_images")
    image_filename = f"page_{page_num + 1}.jpg"
    save_image(image_with_bboxes, os.path.join(image_folder, image_filename))

    image_with_bboxes_folder = os.path.join(output_folder, "page_images_bboxes")
    image_with_bboxes_filename = f"page_{page_num + 1}_bboxes.jpg"
    save_image(image_with_bboxes, os.path.join(image_with_bboxes_folder, image_with_bboxes_filename))

    console.print(f"ğŸ§Š Odinn.Orchestrator: Page {page_num + 1} processed.", style="bold green")
    return page_text, page_meta, images

def process_pdf(filename: str, output_folder: str, settings: Settings, user_metadata: Optional[Dict] = None) -> None:
    """Processes a single PDF file and creates a comprehensive output package."""
    base_name = os.path.basename(filename).rsplit(".", 1)[0]
    project_folder = os.path.join(output_folder, base_name)

    # Create project folder and subfolders
    create_directories(project_folder, ["original_pdf", "page_images", "page_images_bboxes", "page_data"])

    # Copy original PDF
    shutil.copy(filename, os.path.join(project_folder, "original_pdf", base_name + ".pdf"))

    console.print(f"\nğŸ§Š Odinn.Orchestrator: Loading forensic models...  â™»ï¸  \n", style="bold green")
    model_lst = load_all_models()  # Load models once

    doc = pdfium.PdfDocument(filename)
    total_pages = len(doc)
    doc.file_path = filename  # Store the file path in the document object

    for page_num in range(total_pages):
        page_text, page_meta, images = process_page(doc, page_num, settings, project_folder)

        # Save page data
        subfolder_path = get_subfolder_path(output_folder, os.path.basename(filename))
        text_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}.txt")
        save_file(page_text, text_filename)
        console.print(f"ğŸ§Š Odinn.Orchestrator: Saved text for page {page_num + 1} to {text_filename}.", style="bold blue")
        save_file(json.dumps(page_meta, indent=4), text_filename.rsplit(".", 1)[0] + "_meta.json")
        console.print(f"ğŸ§Š Odinn.Orchestrator: Saved metadata for page {page_num + 1} to {text_filename.rsplit('.', 1)[0] + '_meta.json'}.", style="bold blue")
        for filename, image in images.items():
            save_image(image, os.path.join(subfolder_path, "page_data", filename))
            console.print(f"ğŸ§Š Odinn.Orchestrator: Saved image for page {page_num + 1} to {os.path.join(subfolder_path, 'page_data', filename)}.", style="bold blue")

        # Vision Clean process with combined metadata
        combined_metadata = merge_metadata(user_metadata, {})  # Initially empty vision cleaning metadata
        cleaned_text = process_vision_clean(os.path.join(project_folder, "page_images_bboxes", f"page_{page_num + 1}_bboxes.jpg"), text_filename, combined_metadata)
        cleaned_text_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}_cleaned.txt")
        save_file(cleaned_text, cleaned_text_filename)
        console.print(f"\nğŸ§Š Odinn.Orchestrator: Cleaned text for page {page_num + 1} saved to {cleaned_text_filename}.    \n", style="bold green")

        # Extract metadata from cleaned text
        vision_cleaning_metadata = extract_metadata_from_text(cleaned_text)
        combined_metadata = merge_metadata(user_metadata, vision_cleaning_metadata)
        metadata_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}_metadata.json")
        save_file(json.dumps(combined_metadata, indent=4), metadata_filename)
        console.print(f"Metadata saved to {metadata_filename}.")

    # Extract and save TOC
    toc = get_toc(doc)
    save_file(json.dumps(toc, indent=4), os.path.join(project_folder, "page_data", "toc.json"))

    # ... (perform font analysis, structural analysis, language identification)

    # Generate summary report
    console.print(f"\nğŸ§Š Odinn.Orchestrator: Processing complete!  ğŸ‘  \n", style="bold green")
    console.print(f"Project folder: {project_folder}")
    # ... (print other summary information)

def process_pdf_step_by_step(doc: pdfium.PdfDocument, output_folder: str, settings: Settings, user_metadata: Optional[Dict] = None) -> None:
    """Guides the user through each processing step individually."""
    console.print(f"\nğŸ§Š Odinn.Orchestrator: Step-by-Step Processing  \n", style="bold green")

    total_pages = len(doc)

    while True:
        display_step_by_step_menu(doc, settings, output_folder, user_metadata)
        choice = Prompt.ask("Enter option", choices=["1", "2", "3", "4", "5", "6"], default="6")

        if choice == "1":
            with Progress() as progress:
                for page_num in track(range(total_pages), description="Extracting text and metadata..."):
                    process_page(doc, page_num, settings, output_folder)
            console.print("Text and metadata extraction complete.")
        elif choice == "2":
            display_image_extraction_menu(doc, settings, output_folder)
        elif choice == "3":
            if not user_metadata:
                user_metadata = get_user_metadata()
            page_selection = Prompt.ask("Enter page numbers for vision cleaning (comma-separated, 'all' for all pages):")
            if page_selection.lower() == "all":
                pages_to_clean = list(range(total_pages))
            else:
                try:
                    pages_to_clean = [int(p.strip()) - 1 for p in page_selection.split(",")]
                except ValueError:
                    console.print("[bold red]Error: Invalid page selection.[/]")
                    continue

            with Progress() as progress:
                for page_num in track(pages_to_clean, description="Performing vision cleaning..."):
                    subfolder_path = get_subfolder_path(output_folder, os.path.basename(doc.file_path))
                    text_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}.txt")
                    image_path = os.path.join(output_folder, "page_images_bboxes", f"page_{page_num + 1}_bboxes.jpg")
                    combined_metadata = merge_metadata(user_metadata, {})
                    cleaned_text = process_vision_clean(image_path, text_filename, combined_metadata)
                    cleaned_text_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}_cleaned.txt")
                    save_file(cleaned_text, cleaned_text_filename)
                    console.print(f"Vision cleaning complete for page {page_num + 1}.")

                    # Extract metadata from cleaned text
                    vision_cleaning_metadata = extract_metadata_from_text(cleaned_text)
                    combined_metadata = merge_metadata(user_metadata, vision_cleaning_metadata)
                    metadata_filename = os.path.join(subfolder_path, "page_data", f"page_{page_num + 1}_metadata.json")
                    save_file(json.dumps(combined_metadata, indent=4), metadata_filename)
                    console.print(f"Metadata saved to {metadata_filename}.")
        elif choice == "4":
            generate_output_package(doc, settings, output_folder, user_metadata)
        elif choice == "5":
            state_filepath = Prompt.ask("Enter state file path to save:")
            state = {
                "filename": doc.file_path,
                "output_folder": output_folder,
                "settings": settings.__dict__,
                "user_metadata": user_metadata
            }
            save_state(state, state_filepath)
            console.print(f"Current state saved to: {state_filepath}")
        elif choice == "6":
            break  # Back to main menu

def process_pdf_uber_step(filename: str, output_folder: str, settings: Settings) -> None:
    """Runs all processing steps automatically and saves state after each step."""
    console.print(f"\nğŸ§Š Odinn.Orchestrator: Uber Step Processing  \n", style="bold green")
    if not filename:
        console.print("[bold red]Error: No PDF loaded.[/]")
        return

    user_metadata = get_user_metadata()
    process_pdf(filename, output_folder, settings, user_metadata)

# --- TUI Functions ---
# ... (Other TUI functions from previous steps)

# --- Main Function ---
def main():
    """Main function to run the TUI."""
    settings = Settings()
    user_metadata = None
    filename = None
    loaded_doc = None  # Store the loaded PdfDocument object

    while True:
        os.system("cls" if os.name == "nt" else "clear")
        display_main_menu()
        choice = Prompt.ask("Enter option", choices=["1", "2", "3", "4", "5", "6"], default="1")

        if choice == "1":
            filename = Prompt.ask("Enter PDF file path:")
            if not os.path.exists(filename):
                console.print(f"[bold red]Error: File not found: {filename}[/]")
                filename = None
            else:
                loaded_doc = pdfium.PdfDocument(filename)  # Load the PDF document
                loaded_doc.file_path = filename  # Store the file path
                console.print(f"Loaded PDF: {filename}")
        elif choice == "2":
            display_settings_menu(settings)
        elif choice == "3":
            if loaded_doc:
                process_pdf_step_by_step(loaded_doc, settings.output_folder, settings, user_metadata)
            else:
                console.print("[bold red]Error: No PDF loaded.[/]")
        elif choice == "4":
            if loaded_doc:
                process_pdf_uber_step(filename, settings.output_folder, settings)
            else:
                console.print("[bold red]Error: No PDF loaded.[/]")
        elif choice == "5":
            state_filepath = Prompt.ask("Enter state file path to load:")
            state = load_state(state_filepath)
            if state:
                settings.load_from_dict(state.get("settings", {}))
                filename = state.get("filename")
                if filename and os.path.exists(filename):
                    loaded_doc = pdfium.PdfDocument(filename)
                    loaded_doc.file_path = filename
                output_folder = state.get("output_folder")
                user_metadata = state.get("user_metadata")
                console.print(f"Loaded state from: {state_filepath}")
        elif choice == "6":
            console.print("Exiting ğŸ§Š Odinn AI Forensics Tool...")
            break

if __name__ == "__main__":
    main()
```

**2. `utils.py` (Utility Functions):**

```python
import os
import logging
from typing import List, Dict

from PIL import Image, ImageDraw
from pdf2image import convert_from_path

from rich.console import Console

console = Console()

def create_directories(base_path: str, subfolders: List[str]) -> None:
    """Creates directories if they don't exist."""
    for folder in subfolders:
        os.makedirs(os.path.join(base_path, folder), exist_ok=True)
        logging.debug(f"Created directory: {os.path.join(base_path, folder)}")

def save_file(content: str, path: str, mode: str = "w", encoding: str = "utf-8") -> None:
    """Saves text content to a file."""
    with open(path, mode, encoding=encoding) as f:
        f.write(content)

def save_image(image: Image.Image, path: str) -> None:
    """Saves an image to a file."""
    try:
        image.save(path, "JPEG")
        logging.debug(f"Saved image to {path}")
    except Exception as e:
        logging.error(f"Error saving image to {path}: {e}")
        console.print(f"ğŸ§Š Odinn.Orchestrator: Error saving image: {e}  âŒ", style="bold red")

def extract_image_with_bboxes(page: pypdfium2.PdfPage, bboxes: List[Dict], settings: Settings, output_path: str) -> None:
    """Extracts a page image and visualizes bounding boxes."""
    # Use pdf2image to extract the image
    images = convert_from_path(page, first_page=1, last_page=1)
    image = images[0]

    # Draw bounding boxes if enabled
    if settings.visualize_bboxes:
        draw = ImageDraw.Draw(image)
        for bbox in bboxes:
            # Filter by bounding box type if specified
            if settings.bbox_types and bbox["label"] not in settings.bbox_types:
                continue
            coords = bbox["coords"]  # Assuming coords are in the format [x0, y0, x1, y1]
            draw.rectangle(coords, outline="red", width=2)  # Customize color and width as needed

    # Save the image
    image.save(output_path, "JPEG")

def get_subfolder_path(out_folder: str, fname: str) -> str:
    base_name = os.path.basename(fname).rsplit(".", 1)[0]
    return os.path.join(out_folder, base_name)
```

**3. `settings.py` (Settings Management):**

```python
# settings.py

import json
from typing import List, Dict, Any, Optional
import torch

from rich.console import Console
from rich.panel import Panel

console = Console()

class Settings:
    def __init__(self):
        # Marker settings
        self.torch_device = self._detect_torch_device()
        self.ocr_engine = "surya"
        self.langs: Optional[List[str]] = None
        self.batch_multiplier = 2
        self.extract_bboxes = False
        self.bbox_types: List[str] = []
        self.visualize_bboxes = True
        # ... other marker settings (add as needed from marker.settings)

        # Vision cleaning settings
        self.vision_model = "ollama/llava-phi3"
        # ... other vision cleaning settings

        # Output settings
        self.output_folder = "output"
        self.citation: Dict[str, str] = {}

    def _detect_torch_device(self) -> str:
        """Auto-detects the best available torch device."""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"

    def load_from_dict(self, data: Dict[str, Any]) -> None:
        """Loads settings from a dictionary."""
        for key, value in data.items():
            if hasattr(self, key):
                setattr(self, key, value)

    def save_to_file(self, filepath: str) -> None:
        """Saves settings to a JSON file."""
        with open(filepath, 'w') as f:
            json.dump(self.__dict__, f, indent=4)

    def __str__(self) -> str:
        """Returns a string representation of the settings."""
        lines = []
        for key, value in self.__dict__.items():
            lines.append(f"- {key}: {value}")
        return "\n".join(lines)
```

**4. `vision_cleaning.py` (Vision Cleaning Logic):**

```python
# vision_cleaning.py

import base64
import logging

import litellm
from litellm import completion

from rich.console import Console

console = Console()

class VisionCleanProcessor:
    """Processes an image and a text file by sending a vision model using litellm."""

    def retrieve_image(self, image_path: str) -> str:
        """Retrieves an image from a path and converts it to a base64 string."""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def retrieve_text(self, text_path: str) -> str:
        """Retrieves text from a path and returns it."""
        with open(text_path, "r", encoding='utf-8') as text_file:
            return text_file.read()

    def send_to_litellm(self, image_base64: str, text: str, metadata: dict) -> str:
        """Sends an image and text to litellm and returns the response."""
        # Construct the prompt with metadata
        prompt = f"Restore this text to its original detail and turn this into utf-8 plain text: {text}\n\n"
        prompt += "Metadata:\n"
        for key, value in metadata.items():
            prompt += f"- {key}: {value}\n"

        response = litellm.completion(
            model="ollama/llava-phi3",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                    ]
                }
            ],
        )
        return response.choices[0].message.content if response.choices else None

def process_vision_clean(image_path: str, text_path: str, metadata: dict) -> str:
    """Processes an image and a text file by sending a vision model using litellm."""
    processor = VisionCleanProcessor()
    image_base64 = processor.retrieve_image(image_path)
    text = processor.retrieve_text(text_path)
    return processor.send_to_litellm(image_base64, text, metadata)
```

**Remember:**

- Place the `marker` folder (with its complete project structure as you provided) in the `odinn_ai_forensics_tool/` directory.
- Install the necessary dependencies: `pypdfium2`, `pdf2image`, `Pillow`, `litellm`, `rich`.

Now you have all the files you need to start testing the ğŸ§Š Odinn AI Forensics Tool! 
